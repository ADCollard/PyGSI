{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/Kevin.Dougherty/GSI_plots')\n",
    "\n",
    "from runDiagnostics import conventional, satellite\n",
    "\n",
    "def calculate_stats(data):\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    var_list = [(x-mean)**2 for x in data]\n",
    "    variance = np.sum(var_list)/(len(var_list)-1)\n",
    "    std = np.sqrt(variance)\n",
    "    mx = max(data)\n",
    "    mn = min(data)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(np.square(data)))\n",
    "    \n",
    "    return mn, mx, mean, std, rmse\n",
    "\n",
    "def write_csv(nc_file, csv_dict):\n",
    "    \n",
    "    fields = ['Date', 'min', 'max', 'mean', 'std', 'rmse']\n",
    "    \n",
    "    # filename of csv file\n",
    "    filename = csv_dict[0]['Date'] + '_' + nc_file.split('/')[-1].split('.')[0] +'.csv'\n",
    "    \n",
    "    # write to csv file\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        # creating a csv dict writer object\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "\n",
    "        # writing headers (filed names)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # writing data rows\n",
    "        writer.writerows(csv_dict)\n",
    "        \n",
    "        return\n",
    "        \n",
    "\n",
    "def main(parsed_yaml_file):\n",
    "    \n",
    "    for group in parsed_yaml_file['diagnostic']:\n",
    "        for groupType in group.keys():\n",
    "            \n",
    "            if groupType == 'conventional input':\n",
    "        \n",
    "                nc_file   = group[groupType]['path'][0]\n",
    "                obs_id    = group[groupType]['observation id']\n",
    "                qc_flag   = group[groupType]['qc flag']\n",
    "                DATA_TYPE = group[groupType]['data type'][0]\n",
    "\n",
    "                diag = conventional(nc_file)\n",
    "\n",
    "                data = diag.getData(DATA_TYPE, obs_id, qc_flag)\n",
    "            \n",
    "            elif groupType == 'radiance input':\n",
    "                \n",
    "                nc_file   = group[groupType]['path'][0]\n",
    "                channel   = group[groupType]['channel']\n",
    "                qc_flag   = group[groupType]['qc flag']\n",
    "                DATA_TYPE = group[groupType]['data type'][0]\n",
    "\n",
    "                diag = satellite(nc_file)\n",
    "\n",
    "                data = diag.getData(DATA_TYPE, channel, qc_flag)\n",
    "\n",
    "                lats, lons = diag.get_lat_lon(channel, qc_flag)\n",
    "        \n",
    "            else:\n",
    "                print('File type not recognized. Please address in yaml file.')\n",
    "                return\n",
    "            \n",
    "    \n",
    "            metadata = diag.get_metadata()\n",
    "\n",
    "            mn, mx, mean, std, rmse = calculate_stats(data)\n",
    "\n",
    "            date = metadata['Date'].strftime(\"%Y%m%d%H\")\n",
    "\n",
    "            # dictionary of values needed in csv\n",
    "            csv_dict = [{'Date' : date,\n",
    "                        'min'  : mn,\n",
    "                        'max'  : mx,\n",
    "                        'mean' : mean,\n",
    "                        'std'  : std,\n",
    "                        'rmse' : rmse\n",
    "                       }]\n",
    "\n",
    "            write_csv(nc_file, csv_dict)\n",
    "        \n",
    "    return\n",
    "\n",
    "        \n",
    "#########################################################        \n",
    "\n",
    "\n",
    "file = open('test_YAML.yaml')\n",
    "parsed_yaml_file = yaml.load(file, Loader=yaml.FullLoader)\n",
    "main(parsed_yaml_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out multiple files so I can test concat and plotting csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200920/00/atmos/diag_conv_t_ges.2020092000.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200920/06/atmos/diag_conv_t_ges.2020092006.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200920/12/atmos/diag_conv_t_ges.2020092012.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200920/18/atmos/diag_conv_t_ges.2020092018.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200921/00/atmos/diag_conv_t_ges.2020092100.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200921/06/atmos/diag_conv_t_ges.2020092106.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200921/12/atmos/diag_conv_t_ges.2020092112.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200921/18/atmos/diag_conv_t_ges.2020092118.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200922/00/atmos/diag_conv_t_ges.2020092200.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200922/06/atmos/diag_conv_t_ges.2020092206.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200922/12/atmos/diag_conv_t_ges.2020092212.nc4\n",
      "/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/gdas.20200922/18/atmos/diag_conv_t_ges.2020092218.nc4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/Kevin.Dougherty/GSI_plots')\n",
    "\n",
    "from runDiagnostics import conventional, satellite\n",
    "\n",
    "def calculate_stats(data):\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    var_list = [(x-mean)**2 for x in data]\n",
    "    variance = np.sum(var_list)/(len(var_list)-1)\n",
    "    std = np.sqrt(variance)\n",
    "    mx = max(data)\n",
    "    mn = min(data)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(np.square(data)))\n",
    "    \n",
    "    return mn, mx, mean, std, rmse\n",
    "\n",
    "def write_csv(nc_file, csv_dict):\n",
    "    \n",
    "    fields = ['Date', 'min', 'max', 'mean', 'std', 'rmse']\n",
    "    \n",
    "    # filename of csv file\n",
    "    filename = csv_dict[0]['Date'] + '_' + nc_file.split('/')[-1].split('.')[0] +'.csv'\n",
    "    \n",
    "    # write to csv file\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        # creating a csv dict writer object\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "\n",
    "        # writing headers (filed names)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # writing data rows\n",
    "        writer.writerows(csv_dict)\n",
    "        \n",
    "        return\n",
    "        \n",
    "\n",
    "def main():\n",
    "    \n",
    "    dates = ['20200920', '20200921', '20200922']\n",
    "    hrs   = ['00','06','12','18']\n",
    "    \n",
    "    path  = '/scratch2/NCEPDEV/stmp1/Kevin.Dougherty/ncDiags/'\n",
    "    DATA_TYPE = 'O-F'\n",
    "    \n",
    "    \n",
    "    for d in dates:\n",
    "        for hr in hrs:\n",
    "            \n",
    "            nc_file = f'{path}gdas.{d}/{hr}/atmos/diag_conv_t_ges.{d}{hr}.nc4'\n",
    "            \n",
    "    \n",
    "            print(nc_file)\n",
    "            obs_id  = [120]\n",
    "            qc_flag = []\n",
    "\n",
    "            diag = conventional(nc_file)\n",
    "\n",
    "            data = diag.getData(DATA_TYPE, obs_id, qc_flag)\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         nc_file   = parsed_yaml_file['conventional input']['path']\n",
    "#         channel   = parsed_yaml_file['conventional input']['channel']\n",
    "#         qc_flag   = parsed_yaml_file['conventional input']['qc flag']\n",
    "#         DATA_TYPE = parsed_yaml_file['conventional input']['data type'][0]\n",
    "        \n",
    "#         diag = satellite(nc_file)\n",
    "        \n",
    "#         data = diag.getData(DATA_TYPE, channel, qc_flag)\n",
    "    \n",
    "            metadata = diag.get_metadata()\n",
    "\n",
    "            mn, mx, mean, std, rmse = calculate_stats(data)\n",
    "\n",
    "            date = metadata['Date'].strftime(\"%Y%m%d%H\")\n",
    "\n",
    "            # dictionary of values needed in csv\n",
    "            csv_dict = [{'Date' : date,\n",
    "                        'min'  : mn,\n",
    "                        'max'  : mx,\n",
    "                        'mean' : mean,\n",
    "                        'std'  : std,\n",
    "                        'rmse' : rmse\n",
    "                       }]\n",
    "\n",
    "            write_csv(nc_file, csv_dict)\n",
    "        \n",
    "    return\n",
    "\n",
    "        \n",
    "#########################################################        \n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all csv files in directory, store as pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('/home/Kevin.Dougherty/GSI_plots')\n",
    "\n",
    "files = [i for i in glob.glob('*.csv')]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092100</td>\n",
       "      <td>-49.737965</td>\n",
       "      <td>11.135585</td>\n",
       "      <td>0.125913</td>\n",
       "      <td>1.518926</td>\n",
       "      <td>1.524110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092100</td>\n",
       "      <td>-49.737965</td>\n",
       "      <td>11.135585</td>\n",
       "      <td>0.125913</td>\n",
       "      <td>1.518926</td>\n",
       "      <td>1.524110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020092106</td>\n",
       "      <td>-8.365621</td>\n",
       "      <td>6.158086</td>\n",
       "      <td>0.149694</td>\n",
       "      <td>1.129574</td>\n",
       "      <td>1.139301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020092112</td>\n",
       "      <td>-41.445885</td>\n",
       "      <td>84.909750</td>\n",
       "      <td>0.145960</td>\n",
       "      <td>1.430502</td>\n",
       "      <td>1.437905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020092118</td>\n",
       "      <td>-5.645886</td>\n",
       "      <td>6.786186</td>\n",
       "      <td>0.326647</td>\n",
       "      <td>1.159425</td>\n",
       "      <td>1.204417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092106</td>\n",
       "      <td>-8.365621</td>\n",
       "      <td>6.158086</td>\n",
       "      <td>0.149694</td>\n",
       "      <td>1.129574</td>\n",
       "      <td>1.139301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092112</td>\n",
       "      <td>-41.445885</td>\n",
       "      <td>84.909750</td>\n",
       "      <td>0.145960</td>\n",
       "      <td>1.430502</td>\n",
       "      <td>1.437905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092118</td>\n",
       "      <td>-5.645886</td>\n",
       "      <td>6.786186</td>\n",
       "      <td>0.326647</td>\n",
       "      <td>1.159425</td>\n",
       "      <td>1.204417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092000</td>\n",
       "      <td>-56.482166</td>\n",
       "      <td>48.553932</td>\n",
       "      <td>0.137342</td>\n",
       "      <td>1.638797</td>\n",
       "      <td>1.644514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092006</td>\n",
       "      <td>-6.557517</td>\n",
       "      <td>5.571989</td>\n",
       "      <td>0.135937</td>\n",
       "      <td>1.167907</td>\n",
       "      <td>1.175624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092012</td>\n",
       "      <td>-15.571613</td>\n",
       "      <td>75.657970</td>\n",
       "      <td>0.159299</td>\n",
       "      <td>1.733148</td>\n",
       "      <td>1.740423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092018</td>\n",
       "      <td>-5.329500</td>\n",
       "      <td>7.766129</td>\n",
       "      <td>0.340102</td>\n",
       "      <td>1.233479</td>\n",
       "      <td>1.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092200</td>\n",
       "      <td>-120.506920</td>\n",
       "      <td>13.504765</td>\n",
       "      <td>0.094402</td>\n",
       "      <td>1.519015</td>\n",
       "      <td>1.521921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092206</td>\n",
       "      <td>-7.845194</td>\n",
       "      <td>4.531566</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>1.167916</td>\n",
       "      <td>1.167855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092212</td>\n",
       "      <td>-38.937653</td>\n",
       "      <td>34.201817</td>\n",
       "      <td>0.122275</td>\n",
       "      <td>1.454923</td>\n",
       "      <td>1.460027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020092218</td>\n",
       "      <td>-6.359999</td>\n",
       "      <td>5.550861</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>1.170621</td>\n",
       "      <td>1.173492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         min        max      mean       std      rmse\n",
       "0  2020092100  -49.737965  11.135585  0.125913  1.518926  1.524110\n",
       "0  2020092100  -49.737965  11.135585  0.125913  1.518926  1.524110\n",
       "1  2020092106   -8.365621   6.158086  0.149694  1.129574  1.139301\n",
       "2  2020092112  -41.445885  84.909750  0.145960  1.430502  1.437905\n",
       "3  2020092118   -5.645886   6.786186  0.326647  1.159425  1.204417\n",
       "0  2020092106   -8.365621   6.158086  0.149694  1.129574  1.139301\n",
       "0  2020092112  -41.445885  84.909750  0.145960  1.430502  1.437905\n",
       "0  2020092118   -5.645886   6.786186  0.326647  1.159425  1.204417\n",
       "0  2020092000  -56.482166  48.553932  0.137342  1.638797  1.644514\n",
       "0  2020092006   -6.557517   5.571989  0.135937  1.167907  1.175624\n",
       "0  2020092012  -15.571613  75.657970  0.159299  1.733148  1.740423\n",
       "0  2020092018   -5.329500   7.766129  0.340102  1.233479  1.279330\n",
       "0  2020092200 -120.506920  13.504765  0.094402  1.519015  1.521921\n",
       "0  2020092206   -7.845194   4.531566  0.030787  1.167916  1.167855\n",
       "0  2020092212  -38.937653  34.201817  0.122275  1.454923  1.460027\n",
       "0  2020092218   -6.359999   5.550861  0.088033  1.170621  1.173492"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new csv file from combined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.to_csv( \"combined_diag_conv_t_ges.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
